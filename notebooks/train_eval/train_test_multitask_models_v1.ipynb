{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = os.path.join(os.path.abspath('../../'))\n",
    "repo_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,repo_dir)\n",
    "import pridict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = os.path.join(repo_dir, 'dataset')\n",
    "data_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pridict.pridictv2.utilities import *\n",
    "from pridict.pridictv2.dataset import *\n",
    "from pridict.pridictv2.run_workflow import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-talent",
   "metadata": {},
   "source": [
    "### Generate datatensor partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsize=20\n",
    "outcome_suffix = 'clamped'\n",
    "include_MFE = False\n",
    "if include_MFE:\n",
    "    fsuffix = 'withMFE'\n",
    "else:\n",
    "    fsuffix = 'withoutMFE'\n",
    "    \n",
    "tfolder = 'proc_v2'\n",
    "data_dir = create_directory(os.path.join(repo_dir, 'dataset', tfolder, f'align_{fsuffix}'))\n",
    "\n",
    "dtensor_partitions_lst: list[dict[int, dict[str, PartitionDataTensor]]] = []\n",
    "for outcome_name in ['HEK', 'K562']:\n",
    "    fname = f'dpartitions_{outcome_name}_{outcome_suffix}_wsize{wsize}.pkl'\n",
    "    data_partitions =  ReaderWriter.read_data(os.path.join(data_dir, fname))\n",
    "    fname = f'dtensor_{outcome_name}_{outcome_suffix}_wsize{wsize}.pkl'\n",
    "    dtensor= ReaderWriter.read_data(os.path.join(data_dir, fname))\n",
    "    dtensor_partitions = generate_partition_datatensor(dtensor, data_partitions)\n",
    "    dtensor_partitions_lst.append(dtensor_partitions)\n",
    "    \n",
    "    \n",
    "dtensor_partitions_multidata: dict[int, list[dict[str, PartitionDataTensor]]] = {}\n",
    "for run_num in range(5):\n",
    "    dtensor_partitions_multidata[run_num] = []\n",
    "    for dtensor_partitions in dtensor_partitions_lst:\n",
    "        dtensor_partitions_multidata[run_num].append(dtensor_partitions[run_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-district",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtensor_partitions_multidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtensor_partitions_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-harvard",
   "metadata": {},
   "source": [
    "### Define model and experiment configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-lending",
   "metadata": {},
   "source": [
    "We can assign different gpu device index to a fold index (i.e. id), where we train and test separate models on the different GPU devices. For example, if we have 5 GPU devices, we can assign each one to a fold id and create `run_gpu_map` dictionary as the following:\n",
    "```python\n",
    "run_gpu_map = {i:i for i in range(len(data_partitions))}\n",
    "\n",
    "```\n",
    "The `run_gpu_map` dictionary has keys referring to fold ids and values referring to the GPU device index where the model is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in the current setup, we have one GPU device and hence we will assign the same device to all fold ids\n",
    "run_gpu_map = {i:0 for i in range(len(data_partitions))}\n",
    "run_gpu_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d5f68",
   "metadata": {},
   "source": [
    "### Example definition for model training workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "z_dim = 64\n",
    "num_hidden_layers = 2\n",
    "bidirection=True\n",
    "p_dropout = 0.15\n",
    "rnn_class = nn.GRU\n",
    "nonlin_func = nn.ReLU()\n",
    "l2_reg = 1e-5\n",
    "batch_size = 750\n",
    "num_epochs = 150\n",
    "# loss_func = 'KLDloss'\n",
    "loss_func = 'CEloss'\n",
    "trf_tup = [embed_dim, z_dim,\n",
    "           num_hidden_layers,\n",
    "           bidirection, \n",
    "           p_dropout,\n",
    "           rnn_class, nonlin_func,\n",
    "           l2_reg, batch_size, num_epochs]\n",
    "seqlevel_featdim = len(dtensor_partitions[0]['train'].pe_datatensor.seqlevel_feat_colnames)\n",
    "default_outcomes = ['averageedited', 'averageunedited', 'averageindel']\n",
    "num_t_outcomes = 3\n",
    "experiment_options = {'experiment_desc':'pe_rnn_distribution_multidata',\n",
    "                      'model_name':'PE_RNN_distribution_multidata',\n",
    "                      'annot_embed':8,\n",
    "                      'assemb_opt':'stack',\n",
    "                      'loader_mode':'cycle',\n",
    "                      'run_num':0,\n",
    "                      'fdtype':torch.float32,\n",
    "                      'wsize':wsize,\n",
    "                      'datasets_name':['HEK', 'K562'],\n",
    "                      'target_names': default_outcomes[:num_t_outcomes],\n",
    "                      'weight_func_pointers':[None, None],\n",
    "                      'correctiontype_weights':[None, None],\n",
    "                      'separate_attention_layers':True,\n",
    "                      'separate_seqlevel_embedder':True,\n",
    "                      'seqlevel_featdim': seqlevel_featdim,\n",
    "                      'num_outcomes':num_t_outcomes}\n",
    "mconfig, options = build_config_map(trf_tup, experiment_options, loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "repo_path = repo_dir\n",
    "experiment_desc = experiment_options['experiment_desc']\n",
    "exp_dir = create_directory(os.path.join(repo_path, 'experiments', experiment_desc))\n",
    "time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "tr_val_dir = create_directory(f'exp_{time_stamp}', exp_dir)\n",
    "tr_val_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance(tr_val_dir, dset_names, num_runs, wsize=20):\n",
    "    outcome_names = ['averageedited', 'averageunedited', 'averageindel']\n",
    "    res_lst = []\n",
    "\n",
    "    for run_num in range(num_runs):\n",
    "        pred_df = pd.read_csv(os.path.join(tr_val_dir, 'test', f'run_{run_num}', 'predictions_test.csv'))\n",
    "        mscore, report = compute_performance_multidata_from_df(pred_df, dset_names)\n",
    "        for i_data, dsetname in enumerate(dset_names):\n",
    "            m = mscore.modelscores_lst[i_data]\n",
    "            for tindx, tcol in enumerate(outcome_names):\n",
    "                pearson_score = m.pearson_lst[tindx]\n",
    "                spearman_score =  m.spearman_lst[tindx]\n",
    "                res_lst.append((wsize, run_num, pearson_score, spearman_score, tcol, dsetname))\n",
    "    res_df = pd.DataFrame(res_lst)\n",
    "    res_df.columns = ['wsize', 'run_num', 'pear_score', 'spearman_score', 'outcome_name', 'dsetname']\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-emerald",
   "metadata": {},
   "source": [
    "### Train/test models on the 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-hello",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_map = (mconfig, options)\n",
    "train_val_multidata_run(dtensor_partitions_multidata,\n",
    "                        config_map,\n",
    "                        tr_val_dir, \n",
    "                        run_gpu_map, \n",
    "                        num_epochs=num_epochs) # change num_epochs if you want to do a `dry test` (i.e. fast check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multidata_run(dtensor_partitions_multidata,\n",
    "                   config_map, \n",
    "                   tr_val_dir, \n",
    "                   tr_val_dir, \n",
    "                   run_gpu_map, \n",
    "                   num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-gazette",
   "metadata": {},
   "source": [
    "### Evaluate trained models' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_performance(tr_val_dir, ['HEK', 'K562'], 5, wsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-celtic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dsetnames = ['HEK', 'K562']\n",
    "for dsettype in ('train', 'validation', 'test'):\n",
    "    print(f'--- {dsettype} ---')\n",
    "    for outcome_name in ['averageedited', 'averageunedited', 'averageindel']:\n",
    "        out = build_performance_multidata_dfs(tr_val_dir, 5, dsettype, outcome_name, 'continuous', dsetnames)\n",
    "        for i_data, dsetname in enumerate(dsetnames):\n",
    "            display(out[i_data])\n",
    "            \n",
    "    print('*'*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-cyprus",
   "metadata": {},
   "source": [
    "### Identify the epoch's number in which the model (saved state) achieved best peformance on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update options with wsize and seqlevelfeat_dimension\n",
    "tdir = tr_val_dir\n",
    "for run in range(5):\n",
    "    tlink = os.path.join(tdir, 'train_val', f'run_{run}', 'model_statedict', 'best_epoch.pkl')\n",
    "    print(ReaderWriter.read_data(tlink))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-arrow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
